{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Workflow: Pandas DataFrame ↔ TimeDB\n",
        "\n",
        "This notebook demonstrates a complete workflow using pandas DataFrames with TimeDB:\n",
        "1. Generate sample forecast data in a DataFrame\n",
        "2. Write it to TimeDB\n",
        "3. Read it back\n",
        "4. Perform analysis\n",
        "5. Update with revised forecasts\n",
        "6. Compare forecast revisions\n",
        "\n",
        "This is a realistic example that combines all the concepts from the previous notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from timedb.db import create, insert, read\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Get database connection string\n",
        "conninfo = os.environ.get(\"TIMEDB_DSN\") or os.environ.get(\"DATABASE_URL\")\n",
        "if not conninfo:\n",
        "    raise ValueError(\"Set TIMEDB_DSN or DATABASE_URL environment variable\")\n",
        "\n",
        "# Set up IDs\n",
        "tenant_id = uuid.uuid4()\n",
        "entity_id = uuid.uuid4()\n",
        "\n",
        "# Create schema\n",
        "print(\"Setting up database...\")\n",
        "create.create_schema(conninfo)\n",
        "print(\"✓ Database ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate Forecast Data\n",
        "\n",
        "Let's simulate a forecast workflow. We'll create a DataFrame with forecast values including mean and quantiles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate forecast data for the next 48 hours\n",
        "base_time = datetime(2025, 1, 15, 0, 0, tzinfo=timezone.utc)\n",
        "forecast_time = datetime.now(timezone.utc)  # When the forecast is made\n",
        "\n",
        "# Create hourly timestamps\n",
        "timestamps = [base_time + timedelta(hours=i) for i in range(48)]\n",
        "\n",
        "# Generate forecast values with some realistic patterns\n",
        "np.random.seed(42)  # For reproducibility\n",
        "base_value = 100.0\n",
        "trend = np.linspace(0, 10, 48)  # Gradual upward trend\n",
        "seasonality = 5 * np.sin(2 * np.pi * np.arange(48) / 24)  # Daily cycle\n",
        "noise = np.random.normal(0, 2, 48)  # Random noise\n",
        "\n",
        "mean_values = base_value + trend + seasonality + noise\n",
        "quantile_01 = mean_values - 5 - np.abs(np.random.normal(0, 1, 48))\n",
        "quantile_09 = mean_values + 5 + np.abs(np.random.normal(0, 1, 48))\n",
        "\n",
        "# Create DataFrame\n",
        "df_forecast = pd.DataFrame({\n",
        "    'valid_time': timestamps,\n",
        "    'mean': mean_values,\n",
        "    'quantile:0.1': quantile_01,\n",
        "    'quantile:0.9': quantile_09,\n",
        "})\n",
        "\n",
        "print(\"Forecast DataFrame:\")\n",
        "print(df_forecast.head(10))\n",
        "print(f\"\\nShape: {df_forecast.shape}\")\n",
        "print(f\"Time range: {df_forecast['valid_time'].min()} to {df_forecast['valid_time'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Convert and Write to TimeDB\n",
        "\n",
        "Now we'll convert the DataFrame to TimeDB format and insert it:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to convert DataFrame to TimeDB format\n",
        "def dataframe_multi_keys_to_timedb_rows(\n",
        "    df: pd.DataFrame,\n",
        "    tenant_id: uuid.UUID,\n",
        "    entity_id: uuid.UUID,\n",
        "    valid_time_col: str = 'valid_time',\n",
        "    value_columns: list = None,\n",
        ") -> list:\n",
        "    \"\"\"Convert DataFrame with multiple value columns to TimeDB format.\"\"\"\n",
        "    if value_columns is None:\n",
        "        value_columns = [col for col in df.columns if col != valid_time_col]\n",
        "    \n",
        "    # Melt the DataFrame\n",
        "    df_melted = df.melt(\n",
        "        id_vars=[valid_time_col],\n",
        "        value_vars=value_columns,\n",
        "        var_name='value_key',\n",
        "        value_name='value'\n",
        "    )\n",
        "    \n",
        "    # Convert to TimeDB format\n",
        "    rows = []\n",
        "    for _, row in df_melted.iterrows():\n",
        "        rows.append((\n",
        "            tenant_id,\n",
        "            row[valid_time_col],\n",
        "            entity_id,\n",
        "            row['value_key'],\n",
        "            row['value']\n",
        "        ))\n",
        "    \n",
        "    return rows\n",
        "\n",
        "# Convert to TimeDB format\n",
        "value_rows = dataframe_multi_keys_to_timedb_rows(\n",
        "    df_forecast,\n",
        "    tenant_id=tenant_id,\n",
        "    entity_id=entity_id,\n",
        "    value_columns=['mean', 'quantile:0.1', 'quantile:0.9']\n",
        ")\n",
        "\n",
        "print(f\"Converted {len(value_rows)} rows to TimeDB format\")\n",
        "\n",
        "# Insert into TimeDB\n",
        "run_id_1 = uuid.uuid4()\n",
        "insert.insert_run_with_values(\n",
        "    conninfo,\n",
        "    run_id=run_id_1,\n",
        "    tenant_id=tenant_id,\n",
        "    workflow_id=\"forecast-workflow\",\n",
        "    run_start_time=forecast_time,\n",
        "    known_time=forecast_time,\n",
        "    value_rows=value_rows,\n",
        ")\n",
        "\n",
        "print(f\"✓ Inserted run {run_id_1}\")\n",
        "print(f\"✓ Inserted {len(value_rows)} values\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Read Data Back\n",
        "\n",
        "Let's read the data back and verify it matches what we inserted:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to read TimeDB data as wide DataFrame\n",
        "def read_timedb_to_wide_dataframe(\n",
        "    conninfo: str,\n",
        "    tenant_id: uuid.UUID,\n",
        "    start_valid: datetime = None,\n",
        "    end_valid: datetime = None,\n",
        "    value_keys: list = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Read data from TimeDB and return as wide-format DataFrame.\"\"\"\n",
        "    df = read.read_values_between(\n",
        "        conninfo,\n",
        "        tenant_id=tenant_id,\n",
        "        start_valid=start_valid,\n",
        "        end_valid=end_valid,\n",
        "        mode=\"flat\",\n",
        "    )\n",
        "    \n",
        "    df_reset = df.reset_index()\n",
        "    \n",
        "    if value_keys:\n",
        "        df_reset = df_reset[df_reset['value_key'].isin(value_keys)]\n",
        "    \n",
        "    df_wide = df_reset.pivot(\n",
        "        index='valid_time',\n",
        "        columns='value_key',\n",
        "        values='value'\n",
        "    )\n",
        "    \n",
        "    return df_wide\n",
        "\n",
        "# Read the data back\n",
        "df_read = read_timedb_to_wide_dataframe(\n",
        "    conninfo,\n",
        "    tenant_id=tenant_id,\n",
        "    start_valid=base_time,\n",
        "    end_valid=base_time + timedelta(hours=48),\n",
        "    value_keys=['mean', 'quantile:0.1', 'quantile:0.9']\n",
        ")\n",
        "\n",
        "print(\"Data read from TimeDB:\")\n",
        "print(df_read.head(10))\n",
        "print(f\"\\nShape: {df_read.shape}\")\n",
        "print(f\"\\nColumns: {df_read.columns.tolist()}\")\n",
        "\n",
        "# Verify the data matches\n",
        "print(\"\\n✓ Data successfully read from TimeDB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Visualize the Forecast\n",
        "\n",
        "Let's create a visualization of our forecast:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Plot mean with confidence interval\n",
        "ax.plot(df_read.index, df_read['mean'], label='Mean Forecast', linewidth=2, color='blue')\n",
        "ax.fill_between(\n",
        "    df_read.index,\n",
        "    df_read['quantile:0.1'],\n",
        "    df_read['quantile:0.9'],\n",
        "    alpha=0.3,\n",
        "    color='blue',\n",
        "    label='80% Confidence Interval'\n",
        ")\n",
        "\n",
        "ax.set_title('48-Hour Forecast with Confidence Intervals', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Valid Time', fontsize=12)\n",
        "ax.set_ylabel('Value', fontsize=12)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Forecast visualization created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Insert Revised Forecast\n",
        "\n",
        "Now let's simulate a revised forecast (e.g., after new data becomes available):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Revised forecast (made 3 hours later)\n",
        "revised_time = forecast_time + timedelta(hours=3)\n",
        "\n",
        "# Generate revised values (slightly different)\n",
        "np.random.seed(123)  # Different seed for different values\n",
        "revised_mean = mean_values + np.random.normal(0, 1.5, 48)  # Slight adjustments\n",
        "revised_quantile_01 = revised_mean - 5 - np.abs(np.random.normal(0, 1, 48))\n",
        "revised_quantile_09 = revised_mean + 5 + np.abs(np.random.normal(0, 1, 48))\n",
        "\n",
        "df_forecast_revised = pd.DataFrame({\n",
        "    'valid_time': timestamps,\n",
        "    'mean': revised_mean,\n",
        "    'quantile:0.1': revised_quantile_01,\n",
        "    'quantile:0.9': revised_quantile_09,\n",
        "})\n",
        "\n",
        "print(\"Revised Forecast DataFrame (first 10 rows):\")\n",
        "print(df_forecast_revised.head(10))\n",
        "\n",
        "# Convert and insert\n",
        "value_rows_revised = dataframe_multi_keys_to_timedb_rows(\n",
        "    df_forecast_revised,\n",
        "    tenant_id=tenant_id,\n",
        "    entity_id=entity_id,\n",
        "    value_columns=['mean', 'quantile:0.1', 'quantile:0.9']\n",
        ")\n",
        "\n",
        "run_id_2 = uuid.uuid4()\n",
        "insert.insert_run_with_values(\n",
        "    conninfo,\n",
        "    run_id=run_id_2,\n",
        "    tenant_id=tenant_id,\n",
        "    workflow_id=\"forecast-workflow\",\n",
        "    run_start_time=revised_time,\n",
        "    known_time=revised_time,\n",
        "    value_rows=value_rows_revised,\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Inserted revised run {run_id_2}\")\n",
        "print(f\"✓ Inserted {len(value_rows_revised)} values\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Compare Forecast Revisions\n",
        "\n",
        "Let's compare the original and revised forecasts:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read in overlapping mode to see both forecasts\n",
        "df_overlapping = read.read_values_between(\n",
        "    conninfo,\n",
        "    tenant_id=tenant_id,\n",
        "    start_valid=base_time,\n",
        "    end_valid=base_time + timedelta(hours=48),\n",
        "    mode=\"overlapping\",\n",
        ")\n",
        "\n",
        "df_overlapping_reset = df_overlapping.reset_index()\n",
        "df_overlapping_mean = df_overlapping_reset[df_overlapping_reset['value_key'] == 'mean']\n",
        "\n",
        "# Pivot to compare forecasts\n",
        "df_comparison = df_overlapping_mean.pivot(\n",
        "    index='valid_time',\n",
        "    columns='known_time',\n",
        "    values='value'\n",
        ")\n",
        "\n",
        "print(\"Forecast Comparison (mean values):\")\n",
        "print(df_comparison.head(10))\n",
        "print(f\"\\nShape: {df_comparison.shape}\")\n",
        "print(f\"Forecast times: {df_comparison.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the comparison\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Plot both forecasts\n",
        "for col in df_comparison.columns:\n",
        "    ax.plot(df_comparison.index, df_comparison[col], \n",
        "            label=f'Forecast at {col.strftime(\"%Y-%m-%d %H:%M\")}', \n",
        "            linewidth=2, alpha=0.7)\n",
        "\n",
        "ax.set_title('Forecast Revisions Comparison', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Valid Time', fontsize=12)\n",
        "ax.set_ylabel('Mean Forecast Value', fontsize=12)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate differences\n",
        "if len(df_comparison.columns) == 2:\n",
        "    forecast_1 = df_comparison.iloc[:, 0]\n",
        "    forecast_2 = df_comparison.iloc[:, 1]\n",
        "    differences = forecast_2 - forecast_1\n",
        "    \n",
        "    print(f\"\\nForecast differences (revised - original):\")\n",
        "    print(f\"Mean difference: {differences.mean():.2f}\")\n",
        "    print(f\"Max difference: {differences.max():.2f}\")\n",
        "    print(f\"Min difference: {differences.min():.2f}\")\n",
        "    print(f\"Std deviation: {differences.std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Forecast Accuracy Analysis\n",
        "\n",
        "Let's simulate actual values and compare them with our forecasts:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate \"actual\" values (in reality, these would come from observations)\n",
        "np.random.seed(456)\n",
        "actual_values = mean_values + np.random.normal(0, 3, 48)  # Actual with more noise\n",
        "\n",
        "df_actual = pd.DataFrame({\n",
        "    'valid_time': timestamps,\n",
        "    'actual': actual_values\n",
        "})\n",
        "\n",
        "# Get latest forecast\n",
        "df_latest = read_timedb_to_wide_dataframe(\n",
        "    conninfo,\n",
        "    tenant_id=tenant_id,\n",
        "    start_valid=base_time,\n",
        "    end_valid=base_time + timedelta(hours=48),\n",
        "    value_keys=['mean']\n",
        ")\n",
        "\n",
        "# Compare latest forecast with actuals\n",
        "df_latest_mean = df_latest[['mean']].copy()\n",
        "df_latest_mean['actual'] = df_actual.set_index('valid_time')['actual']\n",
        "df_latest_mean['error'] = df_latest_mean['actual'] - df_latest_mean['mean']\n",
        "df_latest_mean['abs_error'] = df_latest_mean['error'].abs()\n",
        "\n",
        "print(\"Forecast vs Actual Comparison:\")\n",
        "print(df_latest_mean.head(10))\n",
        "\n",
        "print(f\"\\nForecast Accuracy Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {df_latest_mean['abs_error'].mean():.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {np.sqrt((df_latest_mean['error']**2).mean()):.2f}\")\n",
        "print(f\"Mean Error (Bias): {df_latest_mean['error'].mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize forecast vs actual\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "# Top plot: Forecast vs Actual\n",
        "ax1.plot(df_latest_mean.index, df_latest_mean['mean'], \n",
        "         label='Latest Forecast', linewidth=2, color='blue')\n",
        "ax1.plot(df_latest_mean.index, df_latest_mean['actual'], \n",
        "         label='Actual', linewidth=2, color='red', linestyle='--')\n",
        "ax1.set_title('Forecast vs Actual Values', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Value', fontsize=12)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Bottom plot: Error over time\n",
        "ax2.plot(df_latest_mean.index, df_latest_mean['error'], \n",
        "         linewidth=2, color='green', alpha=0.7)\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "ax2.set_title('Forecast Error Over Time', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Valid Time', fontsize=12)\n",
        "ax2.set_ylabel('Error (Actual - Forecast)', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This complete workflow demonstrated:\n",
        "\n",
        "1. ✅ **Data Generation**: Created forecast DataFrames with multiple value keys\n",
        "2. ✅ **Data Writing**: Converted DataFrames to TimeDB format and inserted them\n",
        "3. ✅ **Data Reading**: Retrieved data from TimeDB as DataFrames\n",
        "4. ✅ **Data Visualization**: Created plots to visualize forecasts\n",
        "5. ✅ **Forecast Revisions**: Inserted revised forecasts and compared them\n",
        "6. ✅ **Analysis**: Compared forecasts with simulated actuals and calculated accuracy metrics\n",
        "\n",
        "**Key Takeaways:**\n",
        "- TimeDB seamlessly integrates with pandas DataFrames\n",
        "- The workflow supports multiple forecast revisions over time\n",
        "- You can easily compare different forecast versions\n",
        "- The system maintains full history of all forecast revisions\n",
        "- All operations are atomic (no partial writes)\n",
        "\n",
        "**Next Steps:**\n",
        "- Explore the other example notebooks for more specific use cases\n",
        "- Check out the API documentation for REST API usage\n",
        "- Review the workflow examples in `timedb/workflows/` for real-world scenarios\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
