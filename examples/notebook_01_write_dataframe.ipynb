{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Writing Pandas DataFrames to TimeDB\n",
        "\n",
        "This notebook demonstrates how to insert pandas DataFrames directly into TimeDB using the high-level SDK.\n",
        "\n",
        "#### What you'll learn:\n",
        "- Using the TimeDB SDK (`import timedb as td`)\n",
        "- Inserting point-in-time values from DataFrames\n",
        "- Inserting interval values from DataFrames\n",
        "- Handling multiple value keys (e.g., mean, quantiles) - automatic conversion\n",
        "- Working with timezone-aware datetimes\n",
        "\n",
        "**Note:** The SDK automatically handles DataFrame-to-TimeDB format conversion, so you can work directly with pandas DataFrames!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating database schema...\n",
            "✓ Schema created successfully\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import timedb as td\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Create schema (uses TIMEDB_DSN or DATABASE_URL from environment)\n",
        "td.create()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Simple Time Series DataFrame\n",
        "\n",
        "Let's start with a simple DataFrame containing a time series with a single value column. The SDK will automatically convert it to TimeDB format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample DataFrame:\n",
            "                 valid_time  value\n",
            "0 2025-01-01 00:00:00+00:00  100.0\n",
            "1 2025-01-01 01:00:00+00:00  100.5\n",
            "2 2025-01-01 02:00:00+00:00  101.0\n",
            "3 2025-01-01 03:00:00+00:00  101.5\n",
            "4 2025-01-01 04:00:00+00:00  102.0\n",
            "\n",
            "Shape: (24, 2)\n",
            "Time range: 2025-01-01 00:00:00+00:00 to 2025-01-01 23:00:00+00:00\n"
          ]
        }
      ],
      "source": [
        "# Create a simple time series DataFrame\n",
        "base_time = datetime(2025, 1, 1, 0, 0, tzinfo=timezone.utc)\n",
        "dates = [base_time + timedelta(hours=i) for i in range(24)]\n",
        "df = pd.DataFrame({\n",
        "    'valid_time': dates,\n",
        "    'value': [100.0 + i * 0.5 for i in range(24)]\n",
        "})\n",
        "\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df.head())\n",
        "print(f\"\\nShape: {df.shape}\")\n",
        "print(f\"Time range: {df['valid_time'].min()} to {df['valid_time'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the SDK, we can insert the DataFrame directly! The SDK automatically:\n",
        "- Converts the DataFrame to TimeDB format internally\n",
        "- Generates all IDs if not provided (`run_id`, `workflow_id`, `run_start_time`, `entity_id`, `tenant_id`)\n",
        "- Uses the column name as `value_key` (e.g., if column is \"value\", value_key becomes \"value\")\n",
        "- For single-tenant installations, uses a default zeros UUID for `tenant_id`\n",
        "\n",
        "**Under the hood:** The SDK converts each row to `(tenant_id, valid_time, entity_id, value_key, value)` format for point-in-time values.\n",
        "\n",
        "Let's insert with minimal parameters (only DataFrame required!):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared to insert DataFrame with 24 rows\n",
            "DataFrame columns: ['valid_time', 'value']\n",
            "Sample data:\n",
            "                 valid_time  value\n",
            "0 2025-01-01 00:00:00+00:00  100.0\n",
            "1 2025-01-01 01:00:00+00:00  100.5\n",
            "2 2025-01-01 02:00:00+00:00  101.0\n",
            "\n",
            "Note: All IDs (run_id, workflow_id, run_start_time, entity_id, tenant_id) will be auto-generated\n"
          ]
        }
      ],
      "source": [
        "print(f\"Prepared to insert DataFrame with {len(df)} rows\")\n",
        "print(f\"DataFrame columns: {list(df.columns)}\")\n",
        "print(f\"Sample data:\")\n",
        "print(df.head(3))\n",
        "print(\"\\nNote: All IDs (run_id, workflow_id, run_start_time, entity_id, tenant_id) will be auto-generated\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's insert the data into TimeDB using the SDK:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data values inserted successfully.\n",
            "✓ Successfully inserted run 21b40dce-154e-4a3c-9be6-64dfebd6eb16\n",
            "✓ Tenant ID: 00000000-0000-0000-0000-000000000000 (default zeros UUID for single-tenant)\n",
            "✓ Workflow ID: sdk-insert\n",
            "✓ Entity ID: 804f8efe-3f68-4ce7-ba5d-3de870184a9d (save this if you want to update this entity later)\n",
            "✓ Inserted 24 values from DataFrame\n",
            "\n",
            "The value_key used was: 'value' (from the DataFrame column name)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# All optional: tenant_id (defaults to zeros UUID), run_id, workflow_id, \n",
        "# run_start_time, entity_id are auto-generated\n",
        "# value_key is automatically \"value\" (from column name)\n",
        "# The function returns the IDs that were used (including auto-generated ones)\n",
        "\n",
        "result = td.insert_run(df=df)\n",
        "\n",
        "print(f\"✓ Successfully inserted run {result.run_id}\")\n",
        "print(f\"✓ Tenant ID: {result.tenant_id} (default zeros UUID for single-tenant)\")\n",
        "print(f\"✓ Workflow ID: {result.workflow_id}\")\n",
        "print(f\"✓ Entity ID: {result.entity_id} (save this if you want to update this entity later)\")\n",
        "print(f\"✓ Inserted {len(df)} values from DataFrame\")\n",
        "print(f\"\\nThe value_key used was: 'value' (from the DataFrame column name)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: DataFrame with Multiple Value Keys\n",
        "\n",
        "Often you'll have multiple value types in the same DataFrame (e.g., mean, quantiles, min, max). The SDK automatically handles this by melting the DataFrame internally!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame with multiple value columns:\n",
            "                 valid_time   mean  quantile:0.1  quantile:0.9   min    max\n",
            "0 2025-01-02 00:00:00+00:00  100.0          95.0         105.0  90.0  110.0\n",
            "1 2025-01-02 01:00:00+00:00  100.5          95.4         105.6  90.3  110.7\n",
            "2 2025-01-02 02:00:00+00:00  101.0          95.8         106.2  90.6  111.4\n",
            "3 2025-01-02 03:00:00+00:00  101.5          96.2         106.8  90.9  112.1\n",
            "4 2025-01-02 04:00:00+00:00  102.0          96.6         107.4  91.2  112.8\n"
          ]
        }
      ],
      "source": [
        "# Create a DataFrame with multiple value columns\n",
        "base_time = datetime(2025, 1, 2, 0, 0, tzinfo=timezone.utc)\n",
        "dates = [base_time + timedelta(hours=i) for i in range(12)]\n",
        "\n",
        "df_multi = pd.DataFrame({\n",
        "    'valid_time': dates,\n",
        "    'mean': [100.0 + i * 0.5 for i in range(12)],\n",
        "    'quantile:0.1': [95.0 + i * 0.4 for i in range(12)],\n",
        "    'quantile:0.9': [105.0 + i * 0.6 for i in range(12)],\n",
        "    'min': [90.0 + i * 0.3 for i in range(12)],\n",
        "    'max': [110.0 + i * 0.7 for i in range(12)],\n",
        "})\n",
        "\n",
        "print(\"DataFrame with multiple value columns:\")\n",
        "print(df_multi.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SDK automatically melts the DataFrame internally, so each value type becomes a separate row. You can either:\n",
        "- Let the SDK auto-detect all value columns (all columns except `valid_time`)\n",
        "- Explicitly specify which columns to use with `value_columns` parameter\n",
        "\n",
        "Let's insert it:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data values inserted successfully.\n",
            "✓ Successfully inserted run 83331c2d-3ded-4194-b66f-ca160971ba60\n",
            "✓ Entity ID: acebfaef-8d95-446b-8c73-c8ebc7ec3dc3\n",
            "✓ Inserted 60 values (12 rows × 5 value keys)\n",
            "✓ Value keys used: ['mean', 'quantile:0.1', 'quantile:0.9', 'min', 'max']\n"
          ]
        }
      ],
      "source": [
        "# Option 1: Let SDK auto-detect value columns (all except valid_time)\n",
        "# Option 2: Explicitly specify value columns\n",
        "# We'll use option 2 for clarity\n",
        "\n",
        "result_multi = td.insert_run(\n",
        "    df=df_multi,\n",
        "    value_columns=['mean', 'quantile:0.1', 'quantile:0.9', 'min', 'max'],  # SDK will auto-melt these\n",
        "    # Column names become value_keys: 'mean', 'quantile:0.1', etc.\n",
        ")\n",
        "\n",
        "print(f\"✓ Successfully inserted run {result_multi.run_id}\")\n",
        "print(f\"✓ Entity ID: {result_multi.entity_id}\")\n",
        "print(f\"✓ Inserted {len(df_multi) * 5} values (12 rows × 5 value keys)\")\n",
        "print(f\"✓ Value keys used: {['mean', 'quantile:0.1', 'quantile:0.9', 'min', 'max']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data values inserted successfully.\n",
            "✓ Successfully inserted run 8f94b941-b95c-4b2f-8dd5-88582d9f4ee3 (auto-detected columns)\n",
            "✓ Entity ID: 1b1e565e-6d0d-4a3e-95a1-f72ab5d47a05\n",
            "✓ SDK auto-detected value columns: ['mean', 'quantile:0.1', 'quantile:0.9', 'min', 'max']\n"
          ]
        }
      ],
      "source": [
        "# Alternative: Let SDK auto-detect (uses all columns except valid_time)\n",
        "result_multi_auto = td.insert_run(\n",
        "    df=df_multi,\n",
        "    # No value_columns specified - SDK auto-detects all value columns\n",
        "    # Column names automatically become value_keys\n",
        ")\n",
        "\n",
        "print(f\"✓ Successfully inserted run {result_multi_auto.run_id} (auto-detected columns)\")\n",
        "print(f\"✓ Entity ID: {result_multi_auto.entity_id}\")\n",
        "print(f\"✓ SDK auto-detected value columns: {['mean', 'quantile:0.1', 'quantile:0.9', 'min', 'max']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Interval Values\n",
        "\n",
        "TimeDB also supports interval values (values that are valid over a time range). The SDK handles this automatically when you specify the `valid_time_end_col` parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame with intervals\n",
        "base_time = datetime(2025, 1, 3, 0, 0, tzinfo=timezone.utc)\n",
        "\n",
        "df_intervals = pd.DataFrame({\n",
        "    'valid_time': [base_time + timedelta(hours=i*3) for i in range(8)],\n",
        "    'valid_time_end': [base_time + timedelta(hours=(i+1)*3) for i in range(8)],\n",
        "    'value': [50.0 + i * 2.0 for i in range(8)],\n",
        "})\n",
        "\n",
        "print(\"Interval DataFrame:\")\n",
        "print(df_intervals)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For interval values, the SDK automatically converts to:\n",
        "- `(tenant_id, valid_time, valid_time_end, entity_id, value_key, value)`\n",
        "\n",
        "Just specify the `valid_time_end_col` parameter:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert interval values - SDK handles conversion automatically!\n",
        "result_intervals = td.insert_run(\n",
        "    df=df_intervals,\n",
        "    valid_time_end_col='valid_time_end',  # Specify the interval end column\n",
        "    # value_key will be \"value\" (from column name) if not specified\n",
        "    # All IDs auto-generated (tenant_id defaults to zeros UUID)\n",
        ")\n",
        "\n",
        "print(f\"✓ Successfully inserted run {result_intervals.run_id}\")\n",
        "print(f\"✓ Entity ID: {result_intervals.entity_id}\")\n",
        "print(f\"✓ Inserted {len(df_intervals)} interval values\")\n",
        "print(f\"✓ Value key used: 'value' (from DataFrame column name)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the SDK\n",
        "\n",
        "The SDK automatically handles DataFrame conversion, but here's what happens under the hood for educational purposes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The SDK internally converts DataFrames to this format:\n",
        "# Point-in-time: (tenant_id, valid_time, entity_id, value_key, value)\n",
        "# Interval: (tenant_id, valid_time, valid_time_end, entity_id, value_key, value)\n",
        "\n",
        "# For multiple value columns, the SDK automatically:\n",
        "# 1. Melts the DataFrame (converts wide to long format)\n",
        "# 2. Creates rows for each (valid_time, value_key, value) combination\n",
        "# 3. Converts to TimeDB tuple format\n",
        "\n",
        "# Example: What the SDK does internally for df_multi\n",
        "print(\"Original DataFrame (wide format):\")\n",
        "print(df_multi.head(3))\n",
        "print(f\"\\nShape: {df_multi.shape}\")\n",
        "\n",
        "# SDK melts it internally (shown here for demonstration)\n",
        "df_melted_demo = df_multi.melt(\n",
        "    id_vars=['valid_time'],\n",
        "    value_vars=['mean', 'quantile:0.1', 'quantile:0.9', 'min', 'max'],\n",
        "    var_name='value_key',\n",
        "    value_name='value'\n",
        ")\n",
        "print(\"\\nAfter melting (long format - what SDK uses internally):\")\n",
        "print(df_melted_demo.head(6))\n",
        "print(f\"\\nShape: {df_melted_demo.shape}\")\n",
        "print(\"\\nEach row becomes a TimeDB value row with the value_key from the column name!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SDK Features Summary\n",
        "\n",
        "The SDK provides a simple interface while handling all the complexity:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"SDK Features:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"✓ Automatic DataFrame conversion to TimeDB format\")\n",
        "print(\"✓ Handles single value columns (with value_key parameter)\")\n",
        "print(\"✓ Handles multiple value columns (auto-melts, uses column names as value_keys)\")\n",
        "print(\"✓ Supports point-in-time values (default)\")\n",
        "print(\"✓ Supports interval values (with valid_time_end_col parameter)\")\n",
        "print(\"✓ Auto-detects value columns if not specified\")\n",
        "print(\"✓ Validates timezone-aware datetimes\")\n",
        "print(\"✓ Atomic inserts (all-or-nothing)\")\n",
        "print(\"\\nSimple API:\")\n",
        "print(\"  td.create()  # Create schema\")\n",
        "print(\"  td.insert_run(..., df=df, ...)  # Insert DataFrame\")\n",
        "print(\"\\nNo manual conversion needed - just pass your DataFrame!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "You've learned how to:\n",
        "1. ✅ Use the TimeDB SDK (`import timedb as td`)\n",
        "2. ✅ Insert simple time series DataFrames (single value column)\n",
        "3. ✅ Insert DataFrames with multiple value keys (automatic conversion)\n",
        "4. ✅ Insert interval values (with `valid_time_end_col` parameter)\n",
        "\n",
        "**Key Points:**\n",
        "- Use `td.create()` to set up the database schema\n",
        "- Use `td.insert_run()` with your DataFrame - conversion is automatic!\n",
        "- **Minimal parameters**: Only `df` is required - all IDs are auto-generated!\n",
        "  - `tenant_id` defaults to zeros UUID (00000000-0000-0000-0000-000000000000) for single-tenant\n",
        "  - `run_id`, `workflow_id`, `run_start_time`, `entity_id` are all auto-generated\n",
        "- **Return value**: The function returns `InsertResult` with all IDs used (save `entity_id` for updates!)\n",
        "- **Value keys**: Automatically use column names (e.g., column \"value\" → value_key \"value\")\n",
        "- Specify `value_columns` list for multiple value columns (or let SDK auto-detect)\n",
        "- Specify `valid_time_end_col` for interval values\n",
        "- All datetimes must be timezone-aware (SDK validates this)\n",
        "- For multi-tenant installations, provide `tenant_id` explicitly\n",
        "\n",
        "**Entity ID for Updates:**\n",
        "- If you plan to update a time series later, either:\n",
        "  - Provide `entity_id` when inserting, OR\n",
        "  - Save `result.entity_id` from the return value\n",
        "- Without the `entity_id`, you won't be able to identify which entity to update\n",
        "\n",
        "**Under the hood:**\n",
        "- Point-in-time: `(tenant_id, valid_time, entity_id, value_key, value)`\n",
        "- Intervals: `(tenant_id, valid_time, valid_time_end, entity_id, value_key, value)`\n",
        "- Multiple value columns are automatically melted by the SDK\n",
        "- Column names become value_keys automatically\n",
        "\n",
        "Next: See `notebook_02_read_dataframe.ipynb` to learn how to read data back into pandas DataFrames!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
